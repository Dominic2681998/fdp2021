{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6UHG76fYDIZ"
   },
   "source": [
    "#  Autoencoder  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/auto1.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent space = bottleneck\n",
    "\n",
    "<img src=\"images/ae1.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ae1a.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ae4.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxUGj4fXYDIs"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnQLyZQzYDI0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Some functions to process and display data\n",
    "\n",
    "def preprocess(array):\n",
    "    \"\"\"\n",
    "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
    "    \"\"\"\n",
    "\n",
    "    array = array.astype(\"float32\") / 255.0\n",
    "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
    "    return array\n",
    "\n",
    "\n",
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def display(array1, array2):\n",
    "    \"\"\"\n",
    "    Displays ten random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    images1 = array1[indices, :]\n",
    "    images2 = array2[indices, :]\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(image1.reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(image2.reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtmB3sxNYDJI"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "aIyApaI-YDJK",
    "outputId": "da496a6a-92b8-49b7-b7ac-4153fcf45795"
   },
   "outputs": [],
   "source": [
    "# Since we only need images from the dataset to encode and decode, we\n",
    "# won't use the labels.\n",
    "(train_data, _), (test_data, _) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape the data\n",
    "train_data = preprocess(train_data)\n",
    "test_data = preprocess(test_data)\n",
    "\n",
    "# Create a copy of the data with added noise\n",
    "noisy_train_data = noise(train_data)\n",
    "noisy_test_data = noise(test_data)\n",
    "\n",
    "# Display the train data and a version of it with added noise\n",
    "display(train_data, noisy_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDu4LZa0YDJO"
   },
   "source": [
    "## Build the autoencoder\n",
    "\n",
    "We are going to use the Functional API to build our convolutional autoencoder.\n",
    "Read this for more informatin about functional model\n",
    "\n",
    "https://machinelearningmastery.com/keras-functional-api-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhyNqaZyYDJY",
    "outputId": "81081008-e9d9-430c-9887-ae194c77e891"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(28, 28, 1))    #functional model\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9NzLD5jYDJb"
   },
   "source": [
    "Now we can train our autoencoder using `train_data` as both our input data\n",
    "and target. Notice we are setting up the validation data using the same\n",
    "format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JPQ3SJDYDJg",
    "outputId": "f2840719-59db-444e-9144-77aa4511735d"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x=train_data,\n",
    "    y=train_data,\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_data, test_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHSSC6vkYDJj"
   },
   "source": [
    "Let's predict on our test dataset and display the original image together with\n",
    "the prediction from our autoencoder.\n",
    "\n",
    "Notice how the predictions are pretty close to the original images, although\n",
    "not quite the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "_HLCWaY6YDJl",
    "outputId": "e9e22f49-09d0-41b2-c2d6-203d59862497"
   },
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test_data)\n",
    "display(test_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "he_5LXqcbBlb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4Tz0AQ7YDJy"
   },
   "source": [
    "Now that we know that our autoencoder works, let's retrain it using the noisy\n",
    "data as our input and the clean data as our target. We want our autoencoder to\n",
    "learn how to denoise the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmbRlS6NYDJ0",
    "outputId": "5e9f9520-eebd-4bec-96d7-a0ac8a7477b9"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x=noisy_train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(noisy_test_data, test_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXcnG9-oYDJ1"
   },
   "source": [
    "Let's now predict on the noisy data and display the results of our autoencoder.\n",
    "\n",
    "Notice how the autoencoder does an amazing job at removing the noise from the\n",
    "input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "XCSZZR6BYDJ2",
    "outputId": "cbe717e5-e83e-4602-afd2-69dd6cd4a5f4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(noisy_test_data)\n",
    "display(noisy_test_data, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Variational Auto encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/va1.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/va2.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
